{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seismic bumps\n",
    "### Introducción\n",
    "\n",
    "El dataset elegido se corresponde con un conjunto de datos relacionados con el sector minero, concretamente fueron obtenidos en una mina de carbón de Polonia. El dataser describe, por cada muestra, una situación en la que se ha dado un evento sísmico, describiendo factores que determinan la fuerza del mismo. \n",
    "\n",
    "En estos casos, la estadística es inefectiva para la predicción de eventos, por lo que se requiere del uso de técnicas más avanzadas.\n",
    "\n",
    "A partir de estos datos, se busca determinar, a partir de técnicas de aprendizaje, predecir futuras situaciones, para discernir si son situaciones de peligro o no peligro.\n",
    "\n",
    "Veamos cómo se muestran los datos, y qué relaciones existen entre las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "from sklearn.model_selection import train_test_split,  KFold, cross_val_score, GridSearchCV\n",
    "from scipy import stats\n",
    "# sns.set()\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, classification_report, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "from sklearn import set_config\n",
    "import warnings\n",
    "\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier,ExtraTreesClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "show_html = lambda html: display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m seismic \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./seismic-bumps.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, delimiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Eliminar variables que no son de utilidad para el problema\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m seismic \u001b[38;5;241m=\u001b[39m \u001b[43mseismic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5240\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5251\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5386\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6976\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "seismic = pd.read_csv(\"./seismic-bumps.csv\", header=0, delimiter = ',')\n",
    "# Eliminar variables que no son de utilidad para el problema\n",
    "# seismic = seismic.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de los datos y análisis:\n",
    "# Visualizacion basica\n",
    "seismic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirar medias, desviacion estandar, etc.\n",
    "seismic.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómputo de la frecuencia de valores por variable, en forma de histograma\n",
    "seismic.loc[:,:].hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualización de las relaciones de las variables con la variable objetivo\n",
    "g = sns.PairGrid(seismic[:500], diag_sharey=False)    # Reducimos el número de muestras para facilitar el cómputo\n",
    "g.map_upper(sns.scatterplot);\n",
    "g.map_lower(sns.kdeplot);\n",
    "g.map_diag(sns.kdeplot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación entre la variable objetivo y el resto de variables\n",
    "corr = seismic.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr, mask=mask, cmap='seismic',  center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de los datos\n",
    "\n",
    "El objetivo es predecir si la siguiente estimación tendrá valor class == 0 o class == 1 (no peligro / peligro).\n",
    "\n",
    "Observamos que el dataset consta de 19 atributos y 2584 observaciones. Todos los atributos son numéricos menos seismic, seismoacustic y shift, que son categóricos. La variable objetivo es class, que es un atributo booleano que determina si existe peligro (==1) o no (==0).\n",
    "\n",
    "Observamos que, a priori, ninguno de ellos consta de una distribución normal. Las variables categóricas (seismic, seismoacustic y shift) se corresponden con la peligrosidad de la actividad y el tipo de actividad (shift/coal-getting). Las variables numéricas se refieren a las mediciones registradas de energía, números de baches sísmicos registrados en rangos de energía, estadísticas de energía promedio y máximos de energía y, finalmente, resultado de peligrosidad / no peligrosidad.\n",
    "\n",
    "Observamos también que los valores de los atributos no se reparten de forma homogenea, sino que se concentran en valores determinados, por eso encontramos picos tan altos en los histogramas. \n",
    "\n",
    "En cuanto a la correlación de las variables, encontramos que la variable objetivo \"class\" no tiene una correlación buena con ninguna de las demás variables. Los valores de correlación más cercanos se encuentran entre el 0.2 y 0.3. Por otra parte, sí que observamos buenas correlaciones entre otras variables, siendo la correlación más fuerte entre maxenergy y energy, con un 1 de correlación; rbumps3 con rbumps, con un valor aproximado entre 0.8 y 0.9; y rbumps2 y rbumps, con un valor aproximado de 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolución mediante regresión/clasificación: Estudio preliminar \n",
    "\n",
    "A continuación, queremos ver si el problema se podría resolver mediante una regresión lineal o una clasificación.\n",
    "\n",
    "Para ello, separamos el conjunto de training y de test en proporción 70%/30%, conjuntamente con un preproceso de los atributos categóricos a variables \"dummy\", que nos ayudarán a facilitar la regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = seismic[['seismic','seismoacoustic','shift','genergy','gpuls','gdenergy','gdpuls','ghazard','nbumps','nbumps2','nbumps3','nbumps4','nbumps5','nbumps6','nbumps7','nbumps89','energy','maxenergy']]\n",
    "X = seismic.drop(columns=['class'])\n",
    "Y = seismic[['class']]\n",
    "\n",
    "X = pd.get_dummies(data=X, drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Instanciamos el modelo LinearRegression \n",
    "lr = LinearRegression();\n",
    "\n",
    "# Ajustamos con los datos de entrenamiento con el método fit\n",
    "lr.fit(X_train,y_train);\n",
    "\n",
    "# Predecimos con el método predict \n",
    "y_pred = lr.predict(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del estudio preliminar\n",
    "\n",
    "Observamos que la predicción con LinearRegression no es buena para este dataset concreto (R² muy bajo) y por ello necesitaremos de otros métodos de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproceso de los datos\n",
    "\n",
    "Antes de entrenar los modelos, queremos ver que los datos son completos, su dimensionalidad es adecuada, los datos están bien codificados, etc.\n",
    "\n",
    "Empezamos de cero, descargando el dataset de nuevo y separando los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "seismic = pd.read_csv(\"./seismic-bumps.csv\", header=0, delimiter = ',')\n",
    "\n",
    "X = seismic.drop(columns=['class'])\n",
    "Y = seismic[['class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detección de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que, efectivamente, el dataset no contiene valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valores anómalos (outliers)\n",
    "\n",
    "Usamos el histograma de valores para ver si existen valores anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:,:].hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos en el histograma que los valores anómalos, como en la gráfica de maxenergy o energy, observamos valores que se alejan de la media, pero eso es debido a existen eventos de una carga energética mayor que ocurren con una frecuencia mucho menor que otras actividades de menor carga energética, por lo que eliminar estos valores sería impropio, ya que lo que queremos predecir son los eventos peligrosos, normalmente de mayor carga energética."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valores incoherentes/incorrectos\n",
    "\n",
    "Usando el histograma anterior, también se pueden ver los valores incoherentes o incorrectos. A primera vista, no parece que existan valores incorrectos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Codificación de variables no continuas o no ordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las variables categóricas en variables dummies usando get_dummies()\n",
    "X = pd.get_dummies(data=X, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Posible eliminación de variables irrelevantes o redundantes\n",
    "\n",
    "Vemos que id no proporciona ningún tipo de información relevante, por lo que lo vamos a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar variables que no son de utilidad para el problema\n",
    "# seismic = seismic.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creación de nuevas variables que puedan ser útiles\n",
    "\n",
    "A priori, no sentimos la necesidad de crear nuevas variables para este problema. Creemos que el dataset ya es lo suficientemente descriptivo para proceder al entrenamiento y las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalización de la variables\n",
    "\n",
    "Normalizaremos las variables. Para ello, utilizamos estandarización:\n",
    "\n",
    "AL FINAL NO LO HACEMOS, ESTO DA PROBLEMAS PARA LA REGRESIÓN LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X.copy()\n",
    "Y_std = Y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_std.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformación de las variables\n",
    "\n",
    "A priori, no encontramos la necesidad de transformar ninguna variable. Puede ser que durante la experiencia del entrenamiento de modelos, veamos problemas y tengamos que volver al preproceso de datos para eliminar/añadir/transformar variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de modelos lineales/cuadráticos y estimación de rendimiento\n",
    "\n",
    "Dado que el dataset especifica que el tipo de problema es de clasificación, tomaremos los siguientes 3 métodos y probaremos cuál de los 3 funciona mejor: regresión logística, Naive Bayes y k-vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primeramente, separamos los conjuntos de training y de test para el futuro entrenamiento de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación en conjuntos de test y entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, Y_std, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "print(np.mean(cross_val_score(lr,X_train,y_train,cv=10, error_score='raise')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los resultados de la cross-validated score son prometedores. Vamos a entrenar un modelo usando este método y veamos su acierto real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(X_train, y_train)\n",
    "lr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(lr_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(lr_model, X_test, y_test, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "print(np.mean(cross_val_score(gnb,X_train,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que es ligeramente inferior a regresión logística, pero veamos los resultados tras la predicción de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = gnb.fit(X_train, y_train)\n",
    "gnb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gnb_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(gnb_model, X_test, y_test, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-nearest neighbours\n",
    "\n",
    "Para usar KNN debemos tener los datos estandarizados, por lo que usamos MinMax scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn =  KNeighborsClassifier()\n",
    "print(np.mean(cross_val_score(knn,X_train_s,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la cross-validated score ofrece resultados teóricos prácticamente idénticos a regresión logística. Veamos los resultados prácticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_neighbors':[1, 3, 5, 7, 11, 15, 30, 50], \n",
    "          'weights':['distance', 'uniform'], \n",
    "          'leaf_size':[1, 5, 10, 20, 30],\n",
    "          'metric': ['l2', 'l1', 'cosine']}\n",
    "\n",
    "results = (0, None, 0) #Punctuation, Model, cv\n",
    "\n",
    "for cv in range(2,10):\n",
    "    knn_gs =  GridSearchCV(knn,param,cv=cv, n_jobs=-1)\n",
    "    knn_gs.fit(X_train_s, y_train[\"class\"]);\n",
    "    score = pd.DataFrame(knn_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').loc[0, 'mean_test_score']\n",
    "\n",
    "    if results[0] < score:\n",
    "        results = (score, knn_gs, cv)\n",
    "    \n",
    "knn_gs = results[1]    \n",
    "print(\"Para KNN, el mejor valor para cv dentro del experimento es:\", results[2], \"con puntuación de:\", results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=5\n",
    "niter = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(knn_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = [str(v) for v in sorted(Y['class'].unique())]\n",
    "\n",
    "print(classification_report(knn_gs.predict(X_test_s), y_test,target_names=cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve\n",
    "\n",
    "Después de entrenar los tres modelos, podemos observar la curva ROC de los tres modelos en conjunto, y valorar cuál de los tres ofrece mejores resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(lr_model, X_test,y_test, pos_label=1, ax=plt.subplot());\n",
    "RocCurveDisplay.from_estimator(gnb_model, X_test,y_test, pos_label=1, ax=plt.subplot());\n",
    "RocCurveDisplay.from_estimator(knn_gs, X_test_s,y_test, pos_label=1, ax=plt.subplot());\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que apreciar que KNN utiliza datos normalizados, de manera que el gráfico no muestra una comparativa muy precisa respecto al resto de gráficas. A partir de esta, obtenemos los siguientes resultados:\n",
    "\n",
    "Observamos que KNN ofrece la mayor relación true positive/false positive en la mayor parte del rango comprendido por la gráfica. Si queremos coger un valor que ofrezca una buena relación, podemos coger el mejor modelo para x=0.4, por ejemplo. Observamos que el mejor resultado lo ofrece KNN.\n",
    "\n",
    "Regresión linear ofrece ligeramente mejores resultados prácticos que KNN, pero obtiene mayor tasa de falsos positivos en relación a los auténticos positivos, por lo que nos quedaremos con KNN.\n",
    "\n",
    "Naive Bayes no lo consideramos porque ofrece menor score que Linear regression y KNN, así como mayor tasa de falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de modelos no lineales y estimación de rendimiento\n",
    "\n",
    "En el estudio de los modelos no lineales, hemos seleccionado los siguientes: MLP, Random Forest y Gradient Boosting. Veamos su entrenamiento y selección de los mejores hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP (Multi-Layer Perceptron)\n",
    "\n",
    "Para utilizar MLP debemos normalizar los datos. Como hemos visto en laboratorio, la estandarización proporciona una mayor convergencia, por lo que el proceso es más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de los datos de entrenamiento y testing\n",
    "sdscaler = StandardScaler()\n",
    "\n",
    "X_train_sd = sdscaler.fit_transform(X_train)\n",
    "X_test_sd = sdscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaración del clasificador MLP con early_stopping para menor sobre ajuste.\n",
    "mlp = MLPClassifier(max_iter=10000, early_stopping=True, n_iter_no_change=15, random_state=0)\n",
    "print(np.mean(cross_val_score(mlp,X_train_sd,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la cross-validation score es similar a KNN. Veamos el acierto práctico cuando se entrena el modelo y se predicen los valores sobre X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'hidden_layer_sizes':[10, 50, 100, 200, 500, 1000], \n",
    "         'activation':['relu', 'logistic', 'identity'], \n",
    "         'learning_rate_init': [0.00001, 0.0001, 0.001, 0.01, 0.1]  }\n",
    "\n",
    "results = (0,None,0) # Score, Model, cv\n",
    "\n",
    "for cv in range(2,10):\n",
    "    mlp =  MLPClassifier(max_iter=10000, early_stopping=True, n_iter_no_change=20,learning_rate='adaptive',random_state=0)\n",
    "    mlp_gs =  GridSearchCV(mlp,param,cv=cv, n_jobs=-1, refit=True)\n",
    "    mlp_gs.fit(X_train_sd, y_train[\"class\"]);\n",
    "    \n",
    "    score = pd.DataFrame(mlp_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='mean_test_score').loc[0,\"mean_test_score\"]\n",
    "    if results[0] < score:\n",
    "        results = (score,mlp_gs,cv)\n",
    "        \n",
    "mlp_gs = results[1]\n",
    "print(\"Para MLP, el mejor valor para cv dentro del experimento es:\", results[2], \"con puntuación de:\", results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(mlp_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en los modelos previos, el resultado práctico es peor que el teórico. Observamos que los mejores hiperparámetros para este entrenamiento son: Activación ReLU, 100 de tamaño de capas ocultas y tasa inicial de aprendizaje a 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'hidden_layer_sizes':[10, 50, 100, 200, 300], \n",
    "'activation':['relu', 'identity', 'logistic'], \n",
    "'alpha':[0.0001, 0.001, 0.01],\n",
    "'momentum': [0.95, 0.90, 0.85, 0.8], \n",
    "'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "'n_iter_no_change':[10, 20, 40, 50], \n",
    "'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "mlp =  MLPClassifier(max_iter=10000,early_stopping=True,random_state=0)\n",
    "mlp_bs =  BayesSearchCV(mlp,param,\n",
    "                        n_iter=niter, \n",
    "                        cv=cv, n_jobs=-1, \n",
    "                        refit=True,random_state=0)\n",
    "mlp_bs.fit(X_train_sd, y_train[\"class\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(mlp_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos con Bayes Search pero no obtenemos resultados mejores. Observamos que los mejores hiperparámetros nos proprocionan una puntuación con una cota superior de 0.93, que en ningún caso se supera, ya sea usando Bayes Search o no. Dado que no podemos mejorarlo, nos quedaremos con el resultado del modelo más simple (el que no utiliza Bayes) para compararlo con el resto de modelos obtenidos.\n",
    "\n",
    "Al final del entrenamiento de los 3 modelos elegidos en la sección de modelos no lineales, veremos la curva ROC y compararemos su comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mlp_bs.predict(X_test), y_test,target_names=cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(mlp_bs, X_test,y_test, ax=plt.subplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf =  RandomForestClassifier(random_state=0)\n",
    "print(np.mean(cross_val_score(rf,X_train_sd,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter=40\n",
    "param = {'n_estimators': [5,10,25,40, 50, 75,100, 200], \n",
    "         'criterion':['gini', 'entropy'], \n",
    "         'max_depth':[None, 1, 2, 3,  5,  8, 9,10,15],\n",
    "         'min_samples_leaf':[1,2,3,5,10]}\n",
    "\n",
    "rf_bs =  BayesSearchCV(rf,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "rf_bs.fit(X_train, y_train[\"class\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(rf_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rf_bs.predict(X_test), y_test,target_names=cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(rf_bs, X_test,y_test, ax=plt.subplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': [5,10,25,40, 50, 75,100, 200], \n",
    "         'loss':['log_loss', 'exponential'], \n",
    "         'criterion':['friedman_mse', 'squared_error'], \n",
    "         'max_depth':[None, 1, 2, 3,  5,  8, 9,10,15],\n",
    "         'min_samples_leaf':[1,2,3,5,10], \n",
    "         'learning_rate':[0.1,0.5, 1,3, 5, 10, 15]}\n",
    "\n",
    "gb =  GradientBoostingClassifier(random_state=0,n_iter_no_change=5)\n",
    "gb_bs =  BayesSearchCV(gb,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "gb_bs.fit(X_train, y_train[\"class\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(gb_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gb_bs.predict(X_test), y_test,target_names=cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(gb_bs, X_test,y_test, ax=plt.subplot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(gb_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='Gradient Boosting');\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='Random Forest');\n",
    "RocCurveDisplay.from_estimator(mlp_gs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"Multi-Layer Perceptron\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como MLP necesita que la entrada esté normalizada (estandarización) la curva ROC no aparece de manera adecuada en comparación al resto de valores, para Gradient Boosting y Random Forest. \n",
    "\n",
    "Si analizamos las gráficas comparables, vemos que la línea de Gradient Boosting casi siempre toma valores más altos en el eje vertical (True positives) que la gráfica de Random Forest, por lo que podemos pensar que Gradient Boosting ofrece mejores resultados (mayor tasa de auténticos positivos en relación a los falsos positivos).\n",
    "\n",
    "Como los resultados de MLP en la práctica son prácticamente iguales a GB y RF, cogeremos como mejor modelo Gradient Boosting, en el apartado de modelos no lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elección final del modelo, justificación y características\n",
    "\n",
    "Del apartado de modelos lineales hemos escogido K Nearest Neighbours, y de los modelos no lineales hemos escogido Gradient Boosting. Veamos las curvas ROC y los datos comparativos para decidirnos sobre el modelo final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(gb_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='Gradient Boosting');\n",
    "RocCurveDisplay.from_estimator(knn_gs, X_test_s,y_test, pos_label=1, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(knn_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(gb_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(knn_gs.predict(X_test_s), y_test,target_names=cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gb_bs.predict(X_test), y_test,target_names=cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la curva ROC podemos observar que Gradient Boosting ofrece mejores resultados en todos los valores del eje horizontal, por lo que de momento consideramos Gradient Boosting como la mejor opción.\n",
    "\n",
    "Si analizamos los valores de mean test score para ambos modelos, vemos que los valores son muy similares, superando KNN a Gradient Boosting por 0.003. La diferencia es mínima, por lo que realmente no podemos añadir diferencia a través de estos datos.\n",
    "\n",
    "Finalmente, observamos que las puntuaciones tras las predicciones sobre el conjunto de test son muy similares también. Para KNN obtenemos unos valores de (0.98, 0.94, 0.96), mientras que para GB tenemos (1.00, 0.95, 0.97). Los valores para GB son ligeramente superiores a KNN, por lo que tomaremos como mejor resultado en este aspecto el modelo de GB.\n",
    "\n",
    "Tras todos los análisis, vemos que GB es mejor que KNN para este dataset en concreto, con una mayor puntuación y menor tasa de falsos positivos por número de auténticos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias\n",
    "\n",
    "Utilizamos citación en formato APA para esta práctica:\n",
    "\n",
    "- UCI Machine Learning Repository: seismic-bumps Data Set. (s. f.). Recuperado 24 de octubre de 2022, de http://archive.ics.uci.edu/ml/datasets/seismic-bumps\n",
    "- haloboy777. (n.d.). Haloboy777/arfftocsv: Arff to CSV converter (python). GitHub. Recuperado 27 de diciembre de 2022, de https://github.com/haloboy777/arfftocsv "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
